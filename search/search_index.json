{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Going from local functions to cloud deployed pipelines in no time ! <code>pypely</code> simplifies and streamlines the definition of pipelines. <code>pypely</code> pipelines can be converted into many well known pipeline frameworks.</p> <p>Warning</p> <p><code>pypely</code> is work in progress. The API Reference shows what is currently usable. Whereas this page also shows the vision of <code>pypely</code>.</p>"},{"location":"#installation","title":"Installation","text":"<p>To install <code>pypely</code> run: </p> <pre><code>pip install pypely\n</code></pre>"},{"location":"#important-links","title":"Important Links","text":"<ul> <li>API Reference</li> <li>Contributing</li> <li>Examples</li> </ul>"},{"location":"#why-should-i-use-pypely","title":"Why should I use <code>pypely</code>?","text":"<p>The pipeline resides at the core of data and machine learning. There are many great libraries that allow you to define and run pipelines in production. So, why another pipeline library? </p> <p>Each library has its own way to define a pipeline. <code>pypely</code> is here to streamline how pipelines are defined. Streamlining the pipeline definitions brings a lot of benefits:</p> <ul> <li>No library lock in.</li> <li>Start locally, deploy later easily.</li> <li>Pipeline basics are automatically covered by <code>pypely</code>. To learn more about that check out the features section</li> <li>Testability of steps is simplified.</li> </ul>"},{"location":"#features","title":"Features","text":"<p>You get the following features with no additional effort when using <code>pypely</code>.</p>"},{"location":"#dependency-detection","title":"Dependency detection","text":"<p>To run pipelines in a remote environment you need to manage the required dependencies. <code>pypely</code> automatically detects the dependecies for each step. This includes packages installed from PyPI as well as dependencies to your local modules. You don't need to worry anymore about the dependencies, <code>pypely</code> is doing this for you.</p>"},{"location":"#compatability-checks","title":"Compatability checks","text":"<p>Pipelines often run for hours - just to fail in one of the last steps. Often times only because an input did not match the previous output. <code>pypely</code> relies on type annotations to check the compatability of each step. The compatability is checked when the pipeline is created. So, errors are catched as early as possible.</p>"},{"location":"CONTRIBUTING/","title":"Nice that you are here!","text":"<p>We are very glad that you are interested in contributing to this project. Please follow this guide as there are some rules. </p>"},{"location":"CONTRIBUTING/#contributing","title":"Contributing","text":"<p>Again, we're thrilled that you'd like to contribute to this project. Your help is essential for keeping it great.</p> <p>Please note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms.</p>"},{"location":"CONTRIBUTING/#issues-and-prs","title":"Issues and PRs","text":"<p>If you have suggestions for how this project could be improved, or want to report a bug, open an issue! We'd love all and any contributions. If you have questions, too, we'd love to hear them.</p> <p>We'd also love PRs. If you're thinking of a large PR, we advise opening up an issue first to talk about it, though! Look at the links below if you're not sure how to open a PR.</p>"},{"location":"CONTRIBUTING/#submitting-a-pull-request","title":"Submitting a pull request","text":"<ol> <li>Fork and clone the repository.</li> <li>Configure and install the dependencies: <code>conda env create -f conda.yaml</code>.</li> <li>Install the pre-commit hooks: <code>pre-commit install</code>. These hooks will format your code, check the typing and ensure that conventional commits are used.</li> <li>Make sure the tests pass on your machine: <code>source .path &amp;&amp; pytest tests examples</code> (If you work on Windows it is recommended to use the Linux Sub System. Otherwise you can set the PYTHONPATH manually or use dot sourcing)</li> <li>Create a new branch: <code>git checkout -b my-branch-name</code>.</li> <li>Make your change, add tests, and make sure the tests still pass.</li> <li>Push to your fork and submit a pull request.</li> <li>Pat your self on the back and wait for your pull request to be reviewed and merged.</li> </ol> <p>Here are a few things you can do that will increase the likelihood of your pull request being accepted:</p> <ul> <li>Use Conventional Commits</li> <li>Write and update tests.</li> <li>Keep your changes as focused as possible. If there are multiple changes you would like to make that are not dependent upon each other, consider submitting them as separate pull requests.</li> <li>Write a good commit message.</li> </ul> <p>Work in Progress pull requests are also welcome to get feedback early on, or if there is something blocked you.</p>"},{"location":"CONTRIBUTING/#resources","title":"Resources","text":"<ul> <li>How to Contribute to Open Source</li> <li>Using Pull Requests</li> <li>GitHub Help</li> </ul>"},{"location":"CONTRIBUTING/#conventional-commits","title":"Conventional Commits","text":"<p> Be sure to read this section. A bot is installed that will deny your pull request if there are no commits in the format of Conventional Commit.</p> <p>The project uses Conventional Commits to automatically detect project versions. Please read the linked guide to understand Conventional Commits (CC). To ensure that you use conventional commits, install the pre-configured pre-commit hooks. One hook will check that you use conventional commits.</p>"},{"location":"reference/","title":"Reference","text":"<p>I am pypely.</p> <p>Welcome to the py pipeline abstraction language.</p>"},{"location":"reference/#pypely.pipeline","title":"pipeline","text":"<pre><code>pipeline(*funcs)\n</code></pre> <p>I chain functions together.</p> <p>I can deal with any number of provided functions. But I need at least one function. Functions that are fead into me need to be typed. The types of the provided functions need to match.</p> Example <pre><code>from pypely import pipeline\n\ndef open_favourite_ide():\n    ...\n\ndef create_new_conda_environment():\n    ...\n\n...\n\nuse_pypely = pipeline(\n    open_favourite_ide,\n    create_new_conda_environment,\n    activate_environment,\n    install_pypely,\n    have_fun_building_pipelines\n)\n\nuse_pypely() # -&gt; \ud83e\udd73\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>funcs</code> <code>Callable</code> <p>The functions that will be chained to form the pipeline.</p> <code>()</code> <p>Returns:</p> Type Description <code>Callable[P, Output]</code> <p>Callable[P, Output]: A callable that forwards the input <code>P</code> to the first function. The output of the first function is passed to the second function, etc.</p> Source code in <code>pypely/core/_functions.py</code> <pre><code>def pipeline(*funcs: Unpack[Tuple[Callable[P, Any], Unpack[Tuple[Callable, ...]], Callable[..., Output]]]) -&gt; Callable[P, Output]:  # type: ignore\n\"\"\"I chain functions together.\n\n    I can deal with any number of provided functions. But I need at least one function.\n    Functions that are fead into me need to be typed.\n    The types of the provided functions need to match.\n\n    Example:\n        ```python\n        from pypely import pipeline\n\n        def open_favourite_ide():\n            ...\n\n        def create_new_conda_environment():\n            ...\n\n        ...\n\n        use_pypely = pipeline(\n            open_favourite_ide,\n            create_new_conda_environment,\n            activate_environment,\n            install_pypely,\n            have_fun_building_pipelines\n        )\n\n        use_pypely() # -&gt; \ud83e\udd73\n        ```\n\n    Args:\n        funcs (Callable): The functions that will be chained to form the pipeline.\n\n    Returns:\n        Callable[P, Output]: A callable that forwards the input `P` to the first function. The output of the first function is passed to the second function, etc.\n    \"\"\"\n    first, *remaining = funcs\n    initial = _wrap_with_error_handling(\n        first\n    )  # Only the second function is wrapped with error handling in check_and_compose\n    _pipeline = reduce(check_and_compose, remaining, initial)\n\n    @memorizable\n    def _call(*args: P.args, **kwargs: P.kwargs) -&gt; Output:\n        with PipelineMemoryContext() as _:\n            return _pipeline(*args, **kwargs)\n\n    _call = define_annotation(_call, funcs[0], funcs[-1].__annotations__[\"return\"])\n    _call = define_signature(_call, funcs[0], funcs[-1].__annotations__[\"return\"])\n\n    return _call\n</code></pre>"},{"location":"reference/#pypely.fork","title":"fork","text":"<pre><code>fork(*funcs)\n</code></pre> <p>I split the output into multiple parallel branches.</p> <p>Each branch recieves the same input = the output of the function previous to <code>fork</code>.</p> <p>Parameters:</p> Name Type Description Default <code>funcs</code> <code>Callable</code> <p>The functions that consume the output of the previous function in parallel.</p> <code>()</code> <p>Returns:</p> Type Description <code>Callable[P, PypelyTuple]</code> <p>Callable[P, PypelyTuple]: A function that provides the output of all provided functions as a tuple</p> Source code in <code>pypely/core/_functions.py</code> <pre><code>def fork(*funcs: Callable[P, Any]) -&gt; Callable[P, PypelyTuple]:\n\"\"\"I split the output into multiple parallel branches.\n\n    Each branch recieves the same input = the output of the function previous to `fork`.\n\n    Args:\n        funcs (Callable): The functions that consume the output of the previous function in parallel.\n\n    Returns:\n        Callable[P, PypelyTuple]: A function that provides the output of all provided functions as a tuple\n    \"\"\"\n\n    @memorizable(allow_ingest=False)  # type: ignore\n    def _fork(*args: P.args, **kwargs: P.kwargs) -&gt; PypelyTuple:\n        return PypelyTuple(*(func(*args, **kwargs) for func in funcs))\n\n    _fork_annotated = define_annotation(_fork, funcs[0], _fork.__annotations__[\"return\"])\n    _fork_signed = define_signature(_fork_annotated, funcs[0], _fork.__annotations__[\"return\"])\n\n    return _fork_signed\n</code></pre>"},{"location":"reference/#pypely.to","title":"to","text":"<pre><code>to(cls, *set_fields)\n</code></pre> <p>I convert multiple branches into an object.</p> <p>I can only be used after fork. My purpose is to bring the created branches back together. The output of each branch will be used to instantiate the object. The output of the first branch will be set as the first attribute of <code>obj</code> etc.</p> <p><code>set_fields</code> can be used to adjust the order in which the outputs are used for instantiation. The following example demonstrates how <code>to</code> can be used with fields to specify to order in which the outputs of <code>fork</code> are used.</p> Example <pre><code>@dataclass\nclass Table:\n    tea: Tea\n    plate: Plate\n    bread: Bread\n    eggs: Eggs\n\n\nmorning_routine = pipeline(\n    wake_up,\n    go_to_kitchen,\n    fork(\n        make_tea,\n        fry_eggs,\n        cut_bread,\n        get_plate\n    ),\n    to(Table, \"tea\", \"eggs\", \"bread\", \"plate\")\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type[T]</code> <p>A class that will be instantiated by the outputs of the previous <code>fork</code></p> required <code>set_fields</code> <code>str</code> <p>This can be used to define the order in which the fields are set. Please check out the example for a better explanation.</p> <code>()</code> <p>Returns:</p> Type Description <code>Callable[[PypelyTuple], T]</code> <p>Callable[[PypelyTuple], T]: A function that will instantiate the object when called</p> Source code in <code>pypely/core/_functions.py</code> <pre><code>def to(cls: Type[T], *set_fields: str) -&gt; Callable[[PypelyTuple], T]:\n\"\"\"I convert multiple branches into an object.\n\n    I can only be used after fork.\n    My purpose is to bring the created branches back together.\n    The output of each branch will be used to instantiate the object.\n    The output of the first branch will be set as the first attribute of `obj` etc.\n\n    `set_fields` can be used to adjust the order in which the outputs are used for instantiation.\n    The following example demonstrates how `to` can be used with fields to specify to order in which the outputs of `fork` are used.\n\n    Example:\n        ```python\n        @dataclass\n        class Table:\n            tea: Tea\n            plate: Plate\n            bread: Bread\n            eggs: Eggs\n\n\n        morning_routine = pipeline(\n            wake_up,\n            go_to_kitchen,\n            fork(\n                make_tea,\n                fry_eggs,\n                cut_bread,\n                get_plate\n            ),\n            to(Table, \"tea\", \"eggs\", \"bread\", \"plate\")\n        )\n        ```\n\n    Args:\n        cls (Type[T]): A class that will be instantiated by the outputs of the previous `fork`\n        set_fields (str): This can be used to define the order in which the fields are set.\n            Please check out the example for a better explanation.\n\n    Returns:\n        Callable[[PypelyTuple], T]: A function that will instantiate the object when called\n    \"\"\"\n\n    @memorizable(allow_ingest=False)  # type: ignore\n    def _to(vals: PypelyTuple) -&gt; T:\n        vals_flattened = _flatten(vals)\n        if not set_fields == ():\n            assert len(vals_flattened) == len(set_fields)\n            fields_named = {field_name: val for field_name, val in zip(set_fields, vals_flattened)}\n            return cls(**fields_named)\n        else:\n            return cls(*vals_flattened)\n\n    def _mock_function(p: PypelyTuple) -&gt; None:\n        pass\n\n    _to_annotated = define_annotation(_to, _mock_function, _to.__annotations__[\"return\"])\n    _to_signed = define_signature(_to_annotated, _mock_function, _to.__annotations__[\"return\"])\n\n    return _to_signed\n</code></pre>"},{"location":"reference/#pypely.merge","title":"merge","text":"<pre><code>merge(func)\n</code></pre> <p>I merge multiple branches.</p> <p>I can only run after <code>fork</code>. I bring multiple branches back together. The given function <code>func</code> will recieve all outputs of the previous <code>fork</code>. <code>func</code> will recieve the outputs in order. <code>func</code> needs to take as many arguments as there are branches</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[P, T]</code> <p>The function that defines the logic for how the branches will be merged.</p> required <p>Returns:</p> Type Description <code>Callable[[PypelyTuple], T]</code> <p>Callable[[PypelyTuple], T]: A function that will apply <code>func</code> to the outputs of the previous <code>fork</code></p> Source code in <code>pypely/core/_functions.py</code> <pre><code>def merge(func: Callable[P, T]) -&gt; Callable[[PypelyTuple], T]:\n\"\"\"I merge multiple branches.\n\n    I can only run after `fork`. I bring multiple branches back together.\n    The given function `func` will recieve all outputs of the previous `fork`.\n    `func` will recieve the outputs in order.\n    `func` needs to take as many arguments as there are branches\n\n    Args:\n        func (Callable[P, T]): The function that defines the logic for how the branches will be merged.\n\n    Returns:\n        Callable[[PypelyTuple], T]: A function that will apply `func` to the outputs of the previous `fork`\n    \"\"\"\n\n    @memorizable(allow_ingest=False)  # type: ignore\n    def _merge(branches: PypelyTuple) -&gt; T:\n        flat_branches = _flatten(branches)\n        return func(*flat_branches)\n\n    def _mock_function(p: PypelyTuple) -&gt; None:\n        pass\n\n    _merge_annotated = define_annotation(_merge, _mock_function, _merge.__annotations__[\"return\"])\n    _merge_signed = define_signature(_merge_annotated, _mock_function, _merge.__annotations__[\"return\"])\n\n    return _merge_signed\n</code></pre>"},{"location":"reference/#pypely.identity","title":"identity","text":"<pre><code>identity(x)\n</code></pre> <p>I forward the given input untouched.</p> <p>This can be useful if you want to forward a result for a later step. As this approach can also make the pipeline hard to understand, it is advised to use pypely.memory.memorizable</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>T</code> <p>Any input</p> required <p>Returns:</p> Name Type Description <code>T</code> <code>T</code> <p>The input is unchanged.</p> Source code in <code>pypely/core/_functions.py</code> <pre><code>def identity(x: T) -&gt; T:\n\"\"\"I forward the given input untouched.\n\n    This can be useful if you want to forward a result for a later step.\n    As this approach can also make the pipeline hard to understand, it is advised to use [pypely.memory.memorizable][]\n\n    Args:\n        x (T): Any input\n\n    Returns:\n        T: The input is unchanged.\n    \"\"\"\n    return x\n</code></pre>"},{"location":"reference/#pypely.components","title":"components","text":"<p>Ignore for now.</p>"},{"location":"reference/#pypely.core","title":"core","text":"<p>I provide core functionalities of python.</p>"},{"location":"reference/#pypely.core.errors","title":"errors","text":"<p>I provide all errors that can occur when interacting with the core of pypely.</p>"},{"location":"reference/#pypely.core.errors.PipelineStepError","title":"PipelineStepError","text":"<pre><code>PipelineStepError(func, exception)\n</code></pre> <p>         Bases: <code>PypelyError</code></p> <p>I will be raised when a step inside a pipeline fails.</p> Source code in <code>pypely/core/errors/_pipeline.py</code> <pre><code>def __init__(self, func: Callable, exception: Exception):\n    message = self.__error_message(func, exception)\n    super(PipelineStepError, self).__init__(message)\n</code></pre>"},{"location":"reference/#pypely.core.errors.ParameterAnnotationsMissingError","title":"ParameterAnnotationsMissingError","text":"<pre><code>ParameterAnnotationsMissingError(func)\n</code></pre> <p>         Bases: <code>PypelyError</code></p> <p>I will be raised if at least one parameter of the function is not type annotated.</p> Source code in <code>pypely/core/errors/_pipeline.py</code> <pre><code>def __init__(self, func: Callable):\n    message = self.__error_message(func)\n    super().__init__(message)\n</code></pre>"},{"location":"reference/#pypely.core.errors.ReturnTypeAnnotationMissingError","title":"ReturnTypeAnnotationMissingError","text":"<pre><code>ReturnTypeAnnotationMissingError(func)\n</code></pre> <p>         Bases: <code>PypelyError</code></p> <p>I will be raised if a function has no return type annotation.</p> Source code in <code>pypely/core/errors/_pipeline.py</code> <pre><code>def __init__(self, func: Callable):\n    message = self.__error_message(func)\n    super().__init__(message)\n</code></pre>"},{"location":"reference/#pypely.core.errors.InvalidParameterAnnotationError","title":"InvalidParameterAnnotationError","text":"<pre><code>InvalidParameterAnnotationError(func, param)\n</code></pre> <p>         Bases: <code>PypelyError</code></p> <p>I will be rasied when an invalid parameter annotation is used.</p> Source code in <code>pypely/core/errors/_pipeline.py</code> <pre><code>def __init__(self, func: Callable, param: inspect.Parameter):\n    message = self.__error_message(func, param)\n    super().__init__(message)\n</code></pre>"},{"location":"reference/#pypely.core.errors.OutputInputDoNotMatchError","title":"OutputInputDoNotMatchError","text":"<pre><code>OutputInputDoNotMatchError(\n    func1, func2, inner_exception=None\n)\n</code></pre> <p>         Bases: <code>PypelyError</code></p> <p>I will be raised when the output does not match the input of the following function.</p> Source code in <code>pypely/core/errors/_pipeline.py</code> <pre><code>def __init__(self, func1: Callable, func2: Callable, inner_exception: Optional[Exception] = None):\n    message = self.__error_message(func1, func2, inner_exception)\n    super().__init__(message)\n</code></pre>"},{"location":"reference/#pypely.memory","title":"memory","text":"<p>I expose functionality to persist step outputs and use them in later steps.</p> <p>This functionality leverages the shift operators <code>&gt;&gt;</code> and <code>&lt;&lt;</code>.  This allows you to store the output of a step and use it later in an other step.  You can either use a string to define a memory entry or <code>pypely.memory.MemoryEntry</code></p> <p>Example: <pre><code>pipeline(\n    func1 &gt;&gt; \"result\",\n    func2,\n    func3,\n    func4 &lt;&lt; \"result\"\n)\n</code></pre></p> <pre><code>result = MemoryEntry()\n\npipeline(\n    func1 &gt;&gt; result,\n    func2,\n    func3,\n    func4 &lt;&lt; result\n)\n</code></pre> <p>The function that consumes the memory entry also consumes the output from the previous step. So from the previous example <code>func4</code> would receive the output of <code>func3</code> and the memory entry <code>result</code>.</p> <p>The types of the memory entries are stored and it is checked if a function is capable to consume a memory entry based on the type information. </p> Memory entry names must be unique <p>The names of memory entries must be unique throughout the code base when using strings. This limitation is given as there is no way to identify the context in which the memory is used during buildtime. The type information is stored during the buildtime. The simplest way to work around this limitation is to use <code>pypely.memory.MemoryEntry</code> as shown in the second example.</p> The memory is context sensitive <p>The usage of memory entries is context sensitive. This means that you can only consume memory entries from that have been created in the same pipeline. Furthermore this means that the usage of memory entries from sub- / parent-pipelines is not possible. This is done to prohibit too complex memory usages. </p> <p>Due to the context sensitivity, the following example will fail:</p> <pre><code>pipeline(\n    func1 &gt;&gt; \"result\",\n    pipeline(\n        func2 &lt;&lt; \"result\",\n        func3,\n        func4\n    ),\n    func5\n)\n</code></pre>"},{"location":"reference/#pypely.memory.MemoryEntry","title":"MemoryEntry","text":"<pre><code>MemoryEntry()\n</code></pre> <p>I can be used to describe a memory entry.</p> <p>This allows to use a clear name which is internally handled as a uuid. In the future <code>memorizable</code> might only support me instead of using strings. If you run into naming conflicts use me instead of a string to reference the memory entry.</p> Example <pre><code>from pypely import pipeline\nfrom pypely.memory import memorizable, MemoryEntry\n\n@memorizable\ndef some_func() -&gt; int:\n    return 42\n\nintermediate_result = MemoryEntry()\npipeline(\n    ...,\n    some_func &gt;&gt; intermediate_result\n)\n</code></pre> Source code in <code>pypely/memory/_wrappers.py</code> <pre><code>def __init__(self):\n    self.id = str(uuid.uuid4())\n</code></pre>"},{"location":"reference/#pypely.memory.memorizable","title":"memorizable","text":"<pre><code>memorizable(func=None, allow_ingest=True)\n</code></pre> <p>I enable a function to interact with the memory.</p> <p>The <code>func</code> parameter is usually not given directly. This is done via decorators. So memorizable can be used in two ways:</p> Example <pre><code>from pypely.memory import memorizable\n\n\n@memorizable\ndef some_func_that_allows_ingest(arg1: int) -&gt; int:\n    ...\n\n\n@memorizable(allow_ingest=False)\ndef some_func_that_does_not_allow_ingest(arg1: int) -&gt; int:\n    ...\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Optional[Callable[P, T]]</code> <p>The function that wants to interact with the memory. Defaults to None.</p> <code>None</code> <code>allow_ingest</code> <code>Optional[bool]</code> <p>This describes if data from the memory can be ingested into the function. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[Callable[[Callable[P, T]], Callable[P, T]], Callable[P, T]]</code> <p>Union[Callable[[Callable[P, T]], Memorizable], Callable[P, T]]: A callable that allows to use the shift operators (<code>&lt;&lt;</code>, <code>&gt;&gt;</code>)</p> Source code in <code>pypely/memory/_wrappers.py</code> <pre><code>def memorizable(\n    func: Optional[Callable[P, T]] = None, allow_ingest: Optional[bool] = True\n) -&gt; Union[Callable[[Callable[P, T]], Callable[P, T]], Callable[P, T]]:\n\"\"\"I enable a function to interact with the memory.\n\n    The `func` parameter is usually not given directly. This is done via decorators. So memorizable can be used in two ways:\n\n    Example:\n        ```python\n        from pypely.memory import memorizable\n\n\n        @memorizable\n        def some_func_that_allows_ingest(arg1: int) -&gt; int:\n            ...\n\n\n        @memorizable(allow_ingest=False)\n        def some_func_that_does_not_allow_ingest(arg1: int) -&gt; int:\n            ...\n        ```\n\n    Args:\n        func (Optional[Callable[P, T]], optional): The function that wants to interact with the memory. Defaults to None.\n        allow_ingest (Optional[bool], optional): This describes if data from the memory can be ingested into the function. Defaults to True.\n\n    Returns:\n        Union[Callable[[Callable[P, T]], Memorizable], Callable[P, T]]: A callable that allows to use the shift operators (`&lt;&lt;`, `&gt;&gt;`)\n    \"\"\"\n    if func is None:\n\n        def _wrap(func: Callable[P, T]) -&gt; Callable[P, T]:\n            return Memorizable(func, allow_ingest)\n\n        return _wrap\n    else:\n        return Memorizable(func, allow_ingest)\n</code></pre>"},{"location":"reference/#pypely.memory.errors","title":"errors","text":"<p>I describe all errors that can occur during memory interaction.</p>"},{"location":"reference/#pypely.memory.errors.MemoryAttributeExistsError","title":"MemoryAttributeExistsError","text":"<pre><code>MemoryAttributeExistsError(message)\n</code></pre> <p>         Bases: <code>AttributeError</code>, <code>PypelyError</code></p> <p>I will be raised if a memory entry already exists.</p> Source code in <code>pypely/memory/errors.py</code> <pre><code>def __init__(self, message):\n    super(AttributeError, self).__init__(message)\n</code></pre>"},{"location":"reference/#pypely.memory.errors.MemoryAttributeNotFoundError","title":"MemoryAttributeNotFoundError","text":"<pre><code>MemoryAttributeNotFoundError(message)\n</code></pre> <p>         Bases: <code>AttributeError</code>, <code>PypelyError</code></p> <p>I will be raised if no memory entry with a given name exists.</p> Source code in <code>pypely/memory/errors.py</code> <pre><code>def __init__(self, message):\n    super(AttributeError, self).__init__(message)\n</code></pre>"},{"location":"reference/#pypely.memory.errors.MemoryIngestNotAllowedError","title":"MemoryIngestNotAllowedError","text":"<pre><code>MemoryIngestNotAllowedError(message)\n</code></pre> <p>         Bases: <code>RuntimeError</code>, <code>PypelyError</code></p> <p>I will be raised if a memory entry is ingested into a function that does not allow this.</p> Source code in <code>pypely/memory/errors.py</code> <pre><code>def __init__(self, message):\n    super(RuntimeError, self).__init__(message)\n</code></pre>"},{"location":"reference/#pypely.memory.errors.MemoryTypeDoesNotMatchError","title":"MemoryTypeDoesNotMatchError","text":"<pre><code>MemoryTypeDoesNotMatchError(message)\n</code></pre> <p>         Bases: <code>RuntimeError</code>, <code>PypelyError</code></p> <p>I will be rasie if the type of a memory entry does not match the parameter type it should be ingested for.</p> Source code in <code>pypely/memory/errors.py</code> <pre><code>def __init__(self, message):\n    super(RuntimeError, self).__init__(message)\n</code></pre>"},{"location":"reference/#pypely.memory.errors.InvalidMemoryAttributeError","title":"InvalidMemoryAttributeError","text":"<pre><code>InvalidMemoryAttributeError(message)\n</code></pre> <p>         Bases: <code>AttributeError</code>, <code>PypelyError</code></p> <p>I will be raised if a value that is ingested into the memory has an invalid type.</p> Source code in <code>pypely/memory/errors.py</code> <pre><code>def __init__(self, message: str) -&gt; None:\n    super().__init__(message)\n</code></pre>"},{"location":"reference/#pypely.memory.errors.NoFreeParameterFound","title":"NoFreeParameterFound","text":"<pre><code>NoFreeParameterFound(message)\n</code></pre> <p>         Bases: <code>AttributeError</code>, <code>PypelyError</code></p> <p>I am raised when there are too many ingests into a function.</p> Source code in <code>pypely/memory/errors.py</code> <pre><code>def __init__(self, message: str) -&gt; None:\n    super().__init__(message)\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":"<p>The following tutorials will show how you can use <code>pypely</code>. In addition to the tutorials there exist executable examples.</p> <p>Note</p> <p>This section will evolve with further development of pypely. Currently there is planned to describe:</p> <ul> <li>How to test <code>pypely</code> pipelines</li> <li>How to use <code>pypely.memorizable.memory</code> for complex use cases</li> </ul>"}]}